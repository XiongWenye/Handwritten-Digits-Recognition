{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5adf7f12",
   "metadata": {},
   "source": [
    "# Create Training Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d99d76",
   "metadata": {},
   "source": [
    "## Group Information\n",
    "Team Name:\n",
    "<br>Participants:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d1cc90",
   "metadata": {},
   "source": [
    "## 0. Introduction to Creating a Training Dataset\n",
    "In this module, we will generate a training dataset based on the kNN algorithm and generate the corresponding feature lib.  \n",
    "  \n",
    "First we will get an image containing 50x100 handwritten digits. We need to extract these 5000 numbers and generate a feature library for the kNN algorithm. At the same time, we will also extract 2500 of these 5000 digits as the test dataset to test our model.  \n",
    "  \n",
    "OpenCV is a powerful visualization library, it provides some functions to help us achieve these. We will implement these functions by calling `cv2.func()`.  \n",
    "\n",
    "kNN is short for k-Nearest Neighbors. It finds a set of k objects in the training set that are closest to the test object, and then assigns a corresponding label to the test object according to the label with highest frequency among the k objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eddc444",
   "metadata": {},
   "source": [
    "## 1. Initialize the Environment\n",
    "First let's initialize our environment. This step includes importing modules and getting project path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f1f63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number detected related\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from lib import imshow\n",
    "import random\n",
    "\n",
    "# get the project path\n",
    "PRJ_PATH = os.getcwd()\n",
    "# OPENCV_data.npz\n",
    "TRAIN_DATA_NAME = \"OPENCV_data.npz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8ddf5a",
   "metadata": {},
   "source": [
    "## 2. Generate the Training Dataset\n",
    "We now need to generate a training dataset for handwritten digits recognition. We will do it step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7285c92c",
   "metadata": {},
   "source": [
    "### Preprocess the Image\n",
    "Read in the *digits.png* which is in the *DigitsLib* and change it to a gray one. \n",
    "  \n",
    "  \n",
    "The *digits.png* has (50x100) numbers, and each number has (20x20) pixels.  \n",
    "Load *digits.png* with `img = cv2.imread(filename)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c874b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdd61e9",
   "metadata": {},
   "source": [
    "If loaded correctly, you would see the shape of the `img` and its content by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7e29df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.shape)\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e65145",
   "metadata": {},
   "source": [
    "Now let's convert the image into a grayscale one with: `grayImg = cv2.cvtColor(src,code)` \n",
    "<br>**src**: Image to be converted.\n",
    "<br>**code**: Color gamut before and after conversion. It can be `cv2.COLOR_BGR2GRAY`, `\n",
    "cv2.COLOR_BGR2RGB`,`cv2.COLOR_BGR2HSV`. Choose the one you need.\n",
    "\n",
    "note: the given *digits.png* is a colorful one, convert it to a **grayscale** image, not a ~binary~ image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e496c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "grayImg = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a24345",
   "metadata": {},
   "source": [
    "### Split the Image\n",
    "Now we are going to split this images into small cells, each cell only contains only one digit. We will use `np.hsplit(arr, indices_or_sections)` for horizontal segmentation, and  use `np.vsplit(arr, indices_or_sections)` for vertical segmentation.\n",
    "<br>**arr**: *Array to be divided into sub-arrays.*\n",
    "<br>**indices_or_sections**: *an integer N, the array will be divided into N equal array along axis.*\n",
    "<br>**Return**: *A list of sub-arrays.*\n",
    "\n",
    "In this step, we will get a two-dimensional list `cells` whose size is (50, 100, 20, 20). That means the list contains 50 rows and 100 columns of digits, and the size of each digit is 20x20 pixels. \n",
    "\n",
    "\n",
    "Complete following cell below to split the grayscale image we get in the last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e61214",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8b951a",
   "metadata": {},
   "source": [
    "Run the following cell to check the split result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086c413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = np.array(cells)\n",
    "print(cells.shape)\n",
    "for cell in random.sample([(i, j) for i in range(50) for j in range(100)], 10):\n",
    "    imshow(cells[cell])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9330233a",
   "metadata": {},
   "source": [
    "### Generate the Dataset\n",
    "Now we are ready to create the training dataset and the testing dataset.  \n",
    "\n",
    "In the previous step, we have already get `cells` with the shape (50,100,20,20). To generate the dataset, we neet to convert each digit in `cells` from a 20x20 array to a 1x400 array. Use `array.reshape(newshape).astype(np.float32)` to achieve it.  \n",
    "\n",
    "- Use all the numbers in *digits.png* as the training data set, and assign these reshaped numbers to `train`.\n",
    "- Use the numbers in the right half of *digits.png*  as the testing dataset, and assign these reshaped numbers to `test`. That means use the digits from column 51 to column 100 in *digits.png* as the testing dataset. \n",
    "\n",
    "Note: training dataset doesn't contain testing dataset in formal maching learning tasks. We are doing so here only for demonstration purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3fd3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set\n",
    "train = \n",
    "print(f\"Shape of the training set: {train.shape}\")\n",
    "\n",
    "# Testing set\n",
    "test = \n",
    "print(f\"Shape of the testing set: {test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f937cf",
   "metadata": {},
   "source": [
    "After we get the training dataset with 5000 rows, wee need to tell the machine the actual number each row represents so that the machine can start learning. This is called *label*ing the data. And this is what we are going to do next.  \n",
    "\n",
    "In the *digits.png*, we can see the pattern that each 5 row chunks have the same digit. Based on this pattern, we will create the labels for the dataset. \n",
    "\n",
    "The code for labeling testing set is given. Now finish the code for the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b4810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.arange(10) # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "# Training set\n",
    "train_labels = \n",
    "# Testing set\n",
    "test_labels = np.repeat(k,5 * 50)[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bc2031",
   "metadata": {},
   "source": [
    "### Training\n",
    "With all the data and labels set, we can now start training our module.\n",
    "\n",
    "First, Create a KNN object with `knn = cv2.ml.KNearest_create()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2d306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8b4b2a",
   "metadata": {},
   "source": [
    "Then let's start training with `knn.train( samples, layout, responses)`!\n",
    "<br>**samples**: Training samples.\n",
    "<br>**layout**: Sample type. It can be `cv2.ml.ROW_SAMPLE`, which means each training sample is a row of samples), or `cv2.ml.COL_SAMPLE` which means each training sample is a column of samples. \n",
    "<br>**responses**: Vector of responses associated with the training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f95b6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.train( , , )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae5698e",
   "metadata": {},
   "source": [
    "## 3. Testing\n",
    "\n",
    "After training, let's do some test with testing dataset, use `knn.findNearest( samples, k)` to do the recognization.\n",
    "<br>**samples**: Input samples.\n",
    "<br>**k**: Number of used nearest neighbors. It should be greater than or equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15e3d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, result, _, _ = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5484a07",
   "metadata": {},
   "source": [
    "Run the cell below to calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7929751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = result==test_labels\n",
    "correct = np.count_nonzero(matches)\n",
    "accuracy = correct/result.size\n",
    "print(f\"{accuracy * 100: 0.02f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eccf19",
   "metadata": {},
   "source": [
    "If we are doing random guesses, the accuracy should be around 10%. This is a pretty impressing result!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4c94c3",
   "metadata": {},
   "source": [
    "## 4. Save the Training Dataset\n",
    "If everything is ok, let's save the tarining Dataset and the corresponding labels for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b22b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = os.path.join(PRJ_PATH, \"TrainingData\", TRAIN_DATA_NAME)\n",
    "np.savez(fileName, train = train, train_labels = train_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
